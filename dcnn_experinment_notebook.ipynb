{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCNN test\n",
    "\n",
    "DCNN test notebook is a place for exploring customized layers of dcnn with tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Do Experinemts on the padding function on tensorflow*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 1 2 3 0 0]\n",
      " [0 0 4 5 6 0 0]\n",
      " [0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "t = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Set up the padding values\n",
    "# [1, 1]: Add 1 pad for \"height(row)\" dimension\n",
    "# [2, 2]: Add 2 pads for \"weight(col)\" dimension\n",
    "paddings = tf.constant([[1, 1,], [2, 2]])\n",
    "\n",
    "t_pad = tf.pad(t, paddings, \"CONSTANT\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    r = sess.run(t_pad)\n",
    "    \n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 2 3 0 0 0 0]\n",
      " [0 0 0 4 5 6 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Set up the padding values asymmetric \n",
    "# [1, 2]: Prepend 1 pad before the values and append 2 pads after the values in dimension 0\n",
    "# [3, 4]: Prepend 3 pads befroe the values and append 4 pads after the values in dimension 1\n",
    "paddings = tf.constant([[1, 2], [3, 4]])\n",
    "\n",
    "t_pad = tf.pad(t, paddings, \"CONSTANT\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    print(sess.run(t_pad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 4, 7)\n",
      "[[[[0 0 0 0 0 0 0]\n",
      "   [0 0 1 2 3 0 0]\n",
      "   [0 0 4 5 6 0 0]\n",
      "   [0 0 0 0 0 0 0]]]]\n"
     ]
    }
   ],
   "source": [
    "t_4d = tf.constant([[[[1, 2, 3], [4, 5, 6]]]])\n",
    "paddings = tf.constant([[0,0], [0,0], [1, 1], [2, 2]])\n",
    "\n",
    "t_pad = tf.pad(t_4d, paddings, \"CONSTANT\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    r = sess.run(t_pad)\n",
    "    print(r.shape)\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: KMaxPooling2D\n",
    "\n",
    "KmaxPooling is a fundamental layer of dynamic cnn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Op implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# 20180604 Lin, Y.D.: Read how tensorflow does padding dynamically. \n",
    "def _kmax_pooling2d(X, pool_size, strides, k, padding):\n",
    "    print('_kmax_pooling2d starts')\n",
    "    h_pool = pool_size[0]\n",
    "    w_pool = pool_size[1]\n",
    "\n",
    "    h_stride = strides[0]\n",
    "    w_stride = strides[1]\n",
    "    \n",
    "    h_pad = padding[0]\n",
    "    w_pad = padding[1]\n",
    "    \n",
    "    # 20180715 LIN, Y.D. Add batch\n",
    "    batch = X.shape[0]\n",
    "    h = X.shape[1]\n",
    "    w = X.shape[2]\n",
    "    \n",
    "    # 20180719 LIN, Y.D. Add channel\n",
    "    channel = X.shape[3]\n",
    "    \n",
    "    # 20180715 LIN, Y.D. Reshaped seems no need with batch argument\n",
    "#     X = np.reshape(X, (h, w, 1))\n",
    "    \n",
    "    # 20180613 LIN, Y.D. padding has been added in class KMaxPooling2D previosly. No Padding need here\n",
    "    if h_stride == 0:\n",
    "        outputs_h = 1\n",
    "    else:\n",
    "        outputs_h = math.ceil((h-h_pool+1)/h_stride)\n",
    "        \n",
    "    if w_stride == 0:\n",
    "        outputs_w = k\n",
    "    else:\n",
    "        outputs_w = k * math.ceil((w-w_pool+1)/w_stride)\n",
    "        \n",
    "#     outputs_h = math.ceil((h-h_pool+1)/h_stride)\n",
    "#     outputs_w = k * math.ceil((w-w_pool+1)/w_stride)\n",
    "    \n",
    "    \n",
    "    # 20180714 LIN, Y.D. Add batch argument\n",
    "    outputs = np.zeros((batch, outputs_h, outputs_w, channel), dtype=np.float64)\n",
    "#     outputs = np.zeros((batch, outputs_h, outputs_w, 1), dtype=np.float64)\n",
    "    \n",
    "#     outputs = np.zeros((outputs_h, outputs_w, 1), dtype=np.float64)\n",
    "    \n",
    "    # 20180714 LIN, Y.D. Case for Stride 0\n",
    "    if h_stride == 0:\n",
    "        h_stride = h\n",
    "        h_bound  = h\n",
    "    else:\n",
    "        h_bound = h-h_pad\n",
    "        \n",
    "    if w_stride == 0:\n",
    "        w_stride = w\n",
    "        w_bound  = w \n",
    "    else:\n",
    "        w_bound = w-w_pad\n",
    "    \n",
    "    # 20180719 LIN, Y.D. Add channel\n",
    "    for _b in range(0, batch):\n",
    "        \n",
    "        for _c in range(0, channel):\n",
    "        \n",
    "            m = 0\n",
    "            for _h in range(0, h_bound, h_stride):\n",
    "            \n",
    "                n = 0\n",
    "                for _w in range(0, w_bound, w_stride):\n",
    "            \n",
    "                    flatten_slice = X[_b, _h:_h+h_pool, _w:_w+w_pool, _c].ravel()\n",
    "                    top_indices = np.sort(\n",
    "                        np.argpartition(flatten_slice, -1*np.arange(k))[h_pool*w_pool-k: h_pool*w_pool])\n",
    "                    outputs[_b, m, n:n+k, _c] = np.reshape(flatten_slice[top_indices], (1, k))\n",
    "            \n",
    "                    n += k\n",
    "                \n",
    "                    if n >= outputs_w:\n",
    "                        break\n",
    "\n",
    "                m += 1\n",
    "                if m >= outputs_h:\n",
    "                    break\n",
    "    \n",
    "    # 20180715 LIN, Y.D. Add batch\n",
    "#     for _b in range(0, batch):\n",
    "        \n",
    "#         m = 0\n",
    "#         for _h in range(0, h_bound, h_stride):\n",
    "            \n",
    "#             n = 0\n",
    "#             for _w in range(0, w_bound, w_stride):\n",
    "            \n",
    "#                 flatten_slice = X[_b, _h:_h+h_pool, _w:_w+w_pool].ravel()\n",
    "#                 top_indices = np.sort(\n",
    "#                     np.argpartition(flatten_slice, -1*np.arange(k))[h_pool*w_pool-k: h_pool*w_pool])\n",
    "    \n",
    "#             # 20180714 LIN, Y.D. Discovery a Bug Here (Fixed)\n",
    "# #             top_indices = np.sort(\n",
    "# #                 np.argpartition(flatten_slice, -1*np.arange(k))[h_pool+w_pool-k: h_pool+w_pool])\n",
    "#                 outputs[_b, m, n:n+k] = np.reshape(flatten_slice[top_indices], (1, k, 1))\n",
    "            \n",
    "#                 n += k\n",
    "                \n",
    "#                 if n >= outputs_w:\n",
    "#                     break\n",
    "\n",
    "#             m += 1\n",
    "#             if m >= outputs_h:\n",
    "#                 break  \n",
    "            \n",
    "    return outputs\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#20180607 LIN, Y.D. \n",
    "class KMaxPooling2D(tf.layers.Layer):\n",
    "    \n",
    "    def __init__(self, pool_size, strides, k, padding='valid', name=None, **kwargs):\n",
    "        \n",
    "        super(KMaxPooling2D, self).__init__(name=name, **kwargs)\n",
    "        \n",
    "        if padding != 'same' and padding != 'valid':\n",
    "            raise ValueError('Invalid Padding Options. Only SAME and VALID are valid.')\n",
    "            \n",
    "        # 20180610 LIN, Y.D. Add the exception when \n",
    "        if strides[0] == 0 and strides[1] == 0:\n",
    "            raise ValueError('Invalid Stride Values: At least 1 stride value should be greater than 0.')\n",
    "\n",
    "        self.k = k\n",
    "        self.padding = padding\n",
    "        self.pool_size = pool_size\n",
    "        self.strides = strides\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        print('call start')\n",
    "        inputs_shape = inputs.get_shape().as_list()\n",
    "        \n",
    "        if len(inputs_shape) < 4:\n",
    "            raise ValueError('The input should be a 4-D tensor')\n",
    "        \n",
    "        h = inputs_shape[1]\n",
    "        w = inputs_shape[2]\n",
    "        \n",
    "        if inputs_shape == [None, None, None, None]:\n",
    "            return [tf.constant([0]), tf.constant([0]), tf.constant([0]), tf.constant([0])]\n",
    "        \n",
    "        h_stride = self.strides[0]\n",
    "        w_stride = self.strides[1]\n",
    "        \n",
    "        h_pool_s = self.pool_size[0]\n",
    "        w_pool_s = self.pool_size[1]\n",
    "        \n",
    "        # 20180612 LIN, Y.D. \n",
    "        pool_size = tf.constant(self.pool_size, dtype=tf.int32)\n",
    "        strides   = tf.constant(self.strides, dtype=tf.int32)\n",
    "        k = tf.constant(self.k, dtype=tf.int32)\n",
    "        padding = tf.constant([0, 0], dtype=tf.int32)\n",
    "        \n",
    "        if self.padding == 'valid':\n",
    "            if ((h - h_pool_s) / h_stride + 1) % 1 != 0:\n",
    "                raise ValueError('The height is invalid')\n",
    "            if ((w - w_pool_s) / w_stride + 1) % 1 != 0:\n",
    "                raise ValueError('The weight is invalid')\n",
    "        \n",
    "        elif self.padding == 'same':\n",
    "            \n",
    "            # 20180713 LIN, Y.D. h_stride/w_stride is 0 case\n",
    "            if h_stride == 0:\n",
    "                h_pad = 0\n",
    "            else:\n",
    "                h_mod = h % h_stride\n",
    "                \n",
    "                if h_mod == 0:\n",
    "                    h_pad = max([h_pool_s - h_stride, 0])\n",
    "                else:\n",
    "                    h_pad = max([h_pool_s - h_mod, 0])\n",
    "                    \n",
    "            if w_stride == 0:\n",
    "                w_pad = 0\n",
    "            else:\n",
    "                w_mod = w % w_stride\n",
    "            \n",
    "                if w_mod == 0:\n",
    "                    w_pad = max([w_pool_s - w_stride, 0])\n",
    "                else:\n",
    "                    w_pad = max([w_pool_s - w_mod, 0])\n",
    "        \n",
    "            # 20180606 Y.D. Padding input with 0.\n",
    "            h_pad_mod_2 = h_pad % 2\n",
    "            w_pad_mod_2 = w_pad % 2\n",
    "        \n",
    "            if h_pad_mod_2 == 0:\n",
    "                h_pad_top, h_pad_bottom = h_pad//2, h_pad//2\n",
    "            else:\n",
    "                h_pad_top, h_pad_bottom = h_pad//2, h_pad//2 + h_pad_mod_2\n",
    "    \n",
    "            if w_pad_mod_2 == 0:\n",
    "                w_pad_left, w_pad_right = w_pad//2, w_pad//2\n",
    "            else:\n",
    "                w_pad_left, w_pad_right = w_pad//2, w_pad//2 + w_pad_mod_2\n",
    "            \n",
    "            pad_vals = tf.constant(\n",
    "                [[0, 0], [h_pad_top, h_pad_bottom], [w_pad_left, w_pad_right], [0, 0]], \n",
    "                dtype=tf.int32)\n",
    "        \n",
    "            inputs = tf.pad(inputs, pad_vals, \"CONSTANT\")\n",
    "            \n",
    "            # 20180612 LIN, Y.D. Update inputs\n",
    "            padding = tf.constant([h_pad_top+h_pad_bottom, w_pad_left+w_pad_right], dtype=tf.int32)\n",
    "        \n",
    "        print('Prepare to enter _kmax_pooling2d')\n",
    "        outputs = tf.py_func(_kmax_pooling2d, [inputs, pool_size, strides, k, padding], tf.float64)\n",
    "        \n",
    "        self.compute_output_shape(inputs_shape)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \n",
    "        print('Computing output shape')\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmax_pooling2d(inputs, pool_size, strides, k, padding, name=None):\n",
    "    return KMaxPooling2D(pool_size, strides, k, padding=padding, name=name).apply(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[3.]\n",
      "   [1.]\n",
      "   [3.]\n",
      "   [2.]\n",
      "   [3.]\n",
      "   [2.]]\n",
      "\n",
      "  [[3.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [2.]\n",
      "   [2.]\n",
      "   [0.]]]]\n",
      "(1, 2, 6, 1)\n",
      "----------\n",
      "Error is caught successfully\n",
      "Invalid Stride Values: At least 1 stride value should be greater than 0.\n",
      "----------\n",
      "[[[[2.]\n",
      "   [3.]\n",
      "   [3.]\n",
      "   [2.]]\n",
      "\n",
      "  [[3.]\n",
      "   [2.]\n",
      "   [2.]\n",
      "   [3.]]]]\n",
      "(1, 2, 4, 1)\n",
      "----------\n",
      "[[[[1.]\n",
      "   [3.]]]]\n",
      "(1, 1, 2, 1)\n",
      "----------\n",
      "[[[[1.]\n",
      "   [3.]]]]\n",
      "(1, 1, 2, 1)\n",
      "----------\n",
      "[[[[1.]\n",
      "   [3.]\n",
      "   [3.]\n",
      "   [0.]]\n",
      "\n",
      "  [[3.]\n",
      "   [0.]\n",
      "   [3.]\n",
      "   [0.]]]]\n",
      "(1, 2, 4, 1)\n",
      "----------\n",
      "The height is invalid\n",
      "Error is caught successfully\n",
      "Test Case 8\n",
      "[[[[3.]\n",
      "   [2.]\n",
      "   [2.]\n",
      "   [1.]\n",
      "   [3.]\n",
      "   [3.]]]]\n",
      "(1, 1, 6, 1)\n",
      "----------\n",
      "Test Case 9:\n",
      "[[[[2.]\n",
      "   [3.]]\n",
      "\n",
      "  [[3.]\n",
      "   [2.]]\n",
      "\n",
      "  [[2.]\n",
      "   [3.]]]]\n",
      "(1, 3, 2, 1)\n",
      "----------\n",
      "Test Case 10:\n",
      "[[[[2.]\n",
      "   [3.]]\n",
      "\n",
      "  [[3.]\n",
      "   [2.]]\n",
      "\n",
      "  [[2.]\n",
      "   [3.]]]\n",
      "\n",
      "\n",
      " [[[2.]\n",
      "   [3.]]\n",
      "\n",
      "  [[3.]\n",
      "   [2.]]\n",
      "\n",
      "  [[2.]\n",
      "   [3.]]]]\n",
      "(2, 3, 2, 1)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# 20180605 LIN, Y.D.\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    test_x = np.array([[[1,1,3], [3,1,2]]], dtype=np.float64)\n",
    "    test_input = tf.placeholder(tf.float64, (1, 2, 3))\n",
    "    test_reshape = tf.reshape(test_input, shape=(1,2,3,1))\n",
    "    \n",
    "    # Test Case 1: \n",
    "    test_layer = kmax_pooling2d(test_reshape, [2, 2], [1, 1], 2, 'same')\n",
    "    res = sess.run(test_layer, feed_dict={ test_input: test_x })\n",
    "    print(res)\n",
    "    print(res.shape)\n",
    "    print('-' * 10)\n",
    "    \n",
    "    # Test Case 2: Test if exception work.\n",
    "    try:\n",
    "        test_layer_2 = kmax_pooling2d(test_reshape, [3, 3], [0, 0], 2, 'same')\n",
    "        res = sess.run(test_layer_2, feed_dict={ test_input: test_x })\n",
    "        print(res)\n",
    "        print(res.shape)\n",
    "    except ValueError as e:\n",
    "        print('Error is caught successfully')\n",
    "        print(e)\n",
    "        pass\n",
    "    print('-' * 10)\n",
    "    \n",
    "#     # Test Case 3: Test Valid\n",
    "    test_x_3 = np.array([[[1, 2, 3], [3, 1, 2], [2, 1, 3]]], dtype=np.float64)\n",
    "    test_input_3 = tf.placeholder(tf.float64, (1, 3, 3))\n",
    "    test_reshape_3 = tf.reshape(test_input_3, (1, 3, 3, 1))\n",
    "    test_layer_3 = kmax_pooling2d(test_reshape_3, [2, 2], [1, 1], 2, 'valid')\n",
    "    res = sess.run(test_layer_3, feed_dict={ test_input_3: test_x_3 })\n",
    "    print(res)\n",
    "    print(res.shape)\n",
    "    print('-' * 10)\n",
    "    \n",
    "    # Test Case 4: If the first stride will cross over the border.\n",
    "    test_layer_4 = kmax_pooling2d(test_reshape_3, [3, 3], [3, 3], 2, 'same')\n",
    "    res = sess.run(test_layer_4, feed_dict={ test_input_3: test_x_3 })\n",
    "    print(res)\n",
    "    print(res.shape)\n",
    "    print('-' * 10)\n",
    "    \n",
    "    # Test Case 5: Continue the previous test, we use valid as padding policy\n",
    "    test_layer_5 = kmax_pooling2d(test_reshape_3, [3, 3], [3, 3], 2, 'valid')\n",
    "    res = sess.run(test_layer_5, feed_dict={ test_input_3: test_x_3 })\n",
    "    print(res)\n",
    "    print(res.shape)\n",
    "    print('-' * 10)\n",
    "    \n",
    "    # Test Case 6: Filter should not bigger than the input matrix\n",
    "    test_layer_6 = kmax_pooling2d(test_reshape_3, [4, 4], [2, 2], 2, 'same')\n",
    "    res = sess.run(test_layer_6, feed_dict={ test_input_3: test_x_3 })\n",
    "    print(res)\n",
    "    print(res.shape)\n",
    "    print('-' * 10)\n",
    "    \n",
    "    # Test Case 7:  \n",
    "    try:\n",
    "        test_layer_7 = kmax_pooling2d(test_reshape_3, [4, 4], [2, 2], 2, 'valid')\n",
    "        res = sess.run(test_layer_7, feed_dict={ test_input_3: test_x_3 })\n",
    "        print(res)\n",
    "        print(res.shape)\n",
    "        print('-' * 10)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        print('Error is caught successfully')\n",
    "        \n",
    "    # Test Case 8: Stride only on width direction\n",
    "    test_layer_8 = kmax_pooling2d(test_reshape_3, [3, 1], [0, 1], 2, 'same')\n",
    "    res = sess.run(test_layer_8, feed_dict={ test_input_3: test_x_3 })\n",
    "    print('Test Case 8')\n",
    "    print(res)\n",
    "    print(res.shape)\n",
    "    print('-' * 10)\n",
    "    \n",
    "    # Test Case 9: Stride only on height direction\n",
    "    test_layer_9 = kmax_pooling2d(test_reshape_3, [1, 3], [1, 0], 2, 'same')\n",
    "    res = sess.run(test_layer_9, feed_dict={ test_input_3: test_x_3 })\n",
    "    print('Test Case 9:')\n",
    "    print(res)\n",
    "    print(res.shape)\n",
    "    print('-' * 10)\n",
    "    \n",
    "#     # Test Case 10: Batch\n",
    "    test_x_4 = np.array([\n",
    "        [[1, 2, 3], [3, 1, 2], [2, 1, 3]],\n",
    "        [[1, 2, 3], [3, 1, 2], [2, 1, 3]]], dtype=np.float64)\n",
    "    test_input_4 = tf.placeholder(tf.float64, (2, 3, 3))\n",
    "    test_reshape_4 = tf.reshape(test_input_4, (2, 3, 3, 1))\n",
    "    test_layer_10 = kmax_pooling2d(test_reshape_4, [1, 3], [1, 0], 2, 'same')\n",
    "    res = sess.run(test_layer_10, feed_dict={ test_input_4: test_x_4 })\n",
    "    print('Test Case 10:')\n",
    "    print(res)\n",
    "    print(res.shape)\n",
    "    print('-' * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a simple model with kmaxpooling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 100\n",
    "maxlen = 100\n",
    "batch_size = 32\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen, padding='pre')\n",
    "padded_x_test  = tf.keras.preprocessing.sequence.pad_sequences(x_test,  maxlen=maxlen, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call start\n",
      "Prepare to enter _kmax_pooling2d\n",
      "Computing output shape\n"
     ]
    }
   ],
   "source": [
    "input_x = tf.placeholder(tf.int64, (batch_size, maxlen))\n",
    "one_hot = tf.one_hot(input_x, 100)\n",
    "conv = tf.layers.conv1d(\n",
    "    one_hot, 64, kernel_size=(100,), strides=1, padding='same',\n",
    "    kernel_initializer=tf.truncated_normal_initializer(stddev=5e-2, dtype=tf.float32),\n",
    "    bias_initializer=tf.truncated_normal_initializer(stddev=5e-2, dtype=tf.float32)\n",
    ")\n",
    "\n",
    "reshape = tf.reshape(conv, [batch_size, maxlen, 1, 64])\n",
    "kmax = kmax_pooling2d(reshape, [100, 1], [0, 1], 2, 'same')\n",
    "kmax.set_shape([32, 1, 2, 64])\n",
    "flatten = tf.layers.flatten(kmax)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init)\n",
    "#     res = sess.run(one_hot, feed_dict={ input_x: padded_x_train[:32] })\n",
    "#     print('one hot:', res.shape)\n",
    "#     print(res)\n",
    "#     res = sess.run(conv, feed_dict={ one_hot: res })\n",
    "#     print('shape of conv1d:', res.shape)\n",
    "#     print(res)\n",
    "#     res = sess.run(reshape, feed_dict={ conv: res })\n",
    "#     print('reshape of conv1d:')\n",
    "#     print(res.shape)\n",
    "#     res = sess.run(kmax, feed_dict={ reshape: res })\n",
    "#     print('kmax:', res.shape)\n",
    "#     print(res)\n",
    "#     res = sess.run(flatten, feed_dict={ kmax: res} )\n",
    "#     print('flatten', res.shape)\n",
    "#     print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/hb/3__tt48x0nvgkfy5cr7skv_c0000gn/T/tmp11lyzczu\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hb/3__tt48x0nvgkfy5cr7skv_c0000gn/T/tmp11lyzczu', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x12e2aa898>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer flatten_1 is incompatible with the layer: its rank is undefined, but the layer requires a defined rank.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-206f8515e8d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m )\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m input_test_fn = tf.estimator.inputs.numpy_input_fn(\n",
      "\u001b[0;32m~/.pyenv/versions/tensorflow-py36/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/tensorflow-py36/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    841\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/tensorflow-py36/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m--> 856\u001b[0;31m           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m    857\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m    858\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/tensorflow-py36/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-206f8515e8d1>\u001b[0m in \u001b[0;36mmodel_fn\u001b[0;34m(features, labels, mode)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mlogits_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mlogits_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-206f8515e8d1>\u001b[0m in \u001b[0;36mconv_net\u001b[0;34m(features, reuse, dropout, is_training)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mkmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmax_pooling2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#         kmax = kmax_pooling2d(reshape, [100, 1], [0, 1], 2, 'same')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/tensorflow-py36/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/tensorflow-py36/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py\u001b[0m in \u001b[0;36mflatten\u001b[0;34m(inputs, outputs_collections, scope)\u001b[0m\n\u001b[1;32m   1488\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Flatten'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1490\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1491\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_named_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_collections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/tensorflow-py36/lib/python3.6/site-packages/tensorflow/python/layers/core.py\u001b[0m in \u001b[0;36mflatten\u001b[0;34m(inputs, name)\u001b[0m\n\u001b[1;32m    413\u001b[0m   \"\"\"\n\u001b[1;32m    414\u001b[0m   \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/tensorflow-py36/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    826\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \"\"\"\n\u001b[0;32m--> 828\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m   def _add_inbound_node(self,\n",
      "\u001b[0;32m~/.pyenv/versions/tensorflow-py36/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m           \u001b[0;31m# Check input assumptions set before layer building, e.g. input rank.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/tensorflow-py36/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m_assert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m           raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[0;32m-> 1174\u001b[0;31m                            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' is incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m                            \u001b[0;34m'its rank is undefined, but the layer requires a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                            'defined rank.')\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer flatten_1 is incompatible with the layer: its rank is undefined, but the layer requires a defined rank."
     ]
    }
   ],
   "source": [
    "def conv_net(features, reuse, dropout, is_training):\n",
    "    \n",
    "    with tf.variable_scope('conv_net', reuse=reuse):\n",
    "#         input_x = tf.placeholder(tf.int64, (batch_size, features))\n",
    "#         reshape = tf.reshape(features, shape=[-1, 100, 1, 1])\n",
    "        one_hot = tf.one_hot(features, 100)\n",
    "        conv = tf.layers.conv1d(\n",
    "            one_hot, 64, kernel_size=(100,), strides=1, padding='same',\n",
    "            kernel_initializer=tf.truncated_normal_initializer(stddev=5e-2, dtype=tf.float32),\n",
    "            bias_initializer=tf.truncated_normal_initializer(stddev=5e-2, dtype=tf.float32)\n",
    "        )\n",
    "\n",
    "        conv = tf.reshape(conv, [batch_size, maxlen, 1, 64])\n",
    "        kmax = kmax_pooling2d(conv, [100, 1], [0, 1], 2, 'same')\n",
    "#         kmax = kmax_pooling2d(reshape, [100, 1], [0, 1], 2, 'same')\n",
    "        fc = tf.contrib.layers.flatten(kmax)\n",
    "        fc = tf.layers.dense(fc, 100)\n",
    "        fc = tf.layers.dropout(fc, rate=dropout, training=is_training)\n",
    "        output = tf.layers.dense(fc, 2)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def model_fn(features, labels, mode):\n",
    "    \n",
    "    logits_train = conv_net(features, False, 0.4, is_training=True)\n",
    "    logits_test = conv_net(features, True, 0.4, is_training=False)\n",
    "    \n",
    "    pred_classes = tf.argmax(logits_test, axis=1)\n",
    "    pred_probs = tf.nn.softmax(logits_test)\n",
    "    \n",
    "    if model == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n",
    "    \n",
    "    loss_op = tf.reduce_mean(\n",
    "        tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_train), \n",
    "        labels=tf.cast(labels, dtype=tf.int32))\n",
    "    optimizer = tf.train.AdamOptimizer(loss_op, global_steps=tf.train.get_global_step())\n",
    "    \n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "    \n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "        mode=mode, \n",
    "        predictions=pred_classes, \n",
    "        loss=loss_op, \n",
    "        eval_metric_ops={'accuracy': acc_op})\n",
    "    \n",
    "    return estim_specs\n",
    "\n",
    "model = tf.estimator.Estimator(model_fn)\n",
    "\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=padded_x_train, \n",
    "    y=y_train,\n",
    "    batch_size=32,\n",
    "    num_epochs=None,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "model.train(input_fn, steps=10)\n",
    "\n",
    "input_test_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=padded_x_test, \n",
    "    y=y_test,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "e = model.evaluate(input_test_fn)\n",
    "\n",
    "e['accuracy']\n",
    "\n",
    "# init = tf.global_variables_initializer()\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init)\n",
    "#     res = sess.run(one_hot, feed_dict={ input_x: padded_x_train[:32] })\n",
    "#     print('one hot:', res.shape)\n",
    "#     print(res)\n",
    "#     res = sess.run(conv, feed_dict={ one_hot: res })\n",
    "#     print('shape of conv1d:', res.shape)\n",
    "#     print(res)\n",
    "#     res = sess.run(reshape, feed_dict={ conv: res })\n",
    "#     print('reshape of conv1d:')\n",
    "#     print(res.shape)\n",
    "#     res = sess.run(kmax, feed_dict={ reshape: res })\n",
    "#     print('kmax:', res.shape)\n",
    "#     print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.22882307],\n",
       "        [-0.3155947 ]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: Folding\n",
    "\n",
    "Folding is introduced before the last KMax layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: Stack a \"non-deep\" dcnn (1)\n",
    "\n",
    "We stack a shallow dcnn to make sure no bug exists in inference stage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: Stack a \"non-deep\" dcnn (2)\n",
    "\n",
    "Train a \"non-deep\" dcnn with varied length as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 3 2 0 4 5 1 7]\n",
      "[2 1 2 3 5 7 4 6]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([3, 4, 2, 1, 5, 7, 2, 6])\n",
    "print(np.argpartition(x, 3))\n",
    "print(x[np.argpartition(x, 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 3 2 0 1 4 7 5]\n",
      "[2 1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "print(np.argpartition(x, -3))\n",
    "print(x[np.argpartition(x, -3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([[[[1, 2, 3], [2, 3, 1], [3, 2, 1]], [[3, 2, 1], [1, 2, 3], [2, 3, 1]], [[2, 1, 3], [1, 2, 3], [3, 1, 2]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 1],\n",
       "       [1, 3]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0, 0:2, 0:2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
